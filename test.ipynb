{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WHOLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import hmean\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, recall_score, precision_score, auc, roc_curve\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_train = pd.read_csv('../processed_data/evaluation_train.csv')\n",
    "eval_test = pd.read_csv('../processed_data/evaluation_test.csv')\n",
    "eval_eval = pd.read_csv('../processed_data/evaluation_eval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result_emb/train_emb.pickle', 'rb') as f:\n",
    "    result_train = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "with open('result_emb/test_emb.pickle', 'rb') as f:\n",
    "    result_test = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "with open('result_emb/eval_emb.pickle', 'rb') as f:\n",
    "    result_eval = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 512), (1400, 512), (1800, 512))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_train.shape, result_test.shape, result_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_norm(mat):\n",
    "    norm_mat = []\n",
    "    for line in mat:\n",
    "        temp = line / np.sqrt(sum(np.power(line, 2)))\n",
    "        norm_mat.append(temp)\n",
    "    norm_mat = np.array(norm_mat)\n",
    "    return norm_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_train_ln = length_norm(result_train)\n",
    "result_test_ln = length_norm(result_test)\n",
    "result_eval_ln = length_norm(result_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_train = np.array(eval_train[eval_train['domain']=='source'].index)\n",
    "target_train = eval_train[eval_train['domain']=='target'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=16, random_state=42).fit(result_train_ln[source_train])\n",
    "centers = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.min(1-np.dot(result_test_ln, centers.transpose()), axis=-1, keepdims=True)\n",
    "b = np.min(1-np.dot(result_test_ln, result_train_ln[target_train].transpose()), axis=-1, keepdims=True)\n",
    "cos = np.minimum(a, b)\n",
    "\n",
    "eval_test['anomaly_score'] = cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine: gearbox, hmean: 58.85\n",
      "Machine: ToyTrain, hmean: 50.98\n",
      "Machine: ToyCar, hmean: 47.32\n",
      "Machine: valve, hmean: 55.77\n",
      "Machine: slider, hmean: 68.70\n",
      "Machine: fan, hmean: 55.64\n",
      "Machine: bearing, hmean: 54.22\n",
      "final score : 55.25\n"
     ]
    }
   ],
   "source": [
    "source_train = np.array(eval_train[eval_train['domain']=='source'].index)\n",
    "target_train = np.array(eval_train[eval_train['domain']=='target'].index)\n",
    "\n",
    "kmeans = KMeans(n_clusters=16, random_state=42).fit(result_train_ln[source_train])\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "a = np.min(1-np.dot(result_train_ln, centers.transpose()), axis=-1, keepdims=True)\n",
    "b = np.min(1-np.dot(result_train_ln, result_train_ln[target_train].transpose()), axis=-1, keepdims=True)\n",
    "cos_train = np.minimum(a, b)\n",
    "eval_train['anomaly_score'] = cos_train\n",
    "\n",
    "a = np.min(1-np.dot(result_test_ln, centers.transpose()), axis=-1, keepdims=True)\n",
    "b = np.min(1-np.dot(result_test_ln, result_train_ln[target_train].transpose()), axis=-1, keepdims=True)\n",
    "cos_test = np.minimum(a, b)\n",
    "eval_test['anomaly_score'] = cos_test\n",
    "\n",
    "a = np.min(1-np.dot(result_eval_ln, centers.transpose()), axis=-1, keepdims=True)\n",
    "b = np.min(1-np.dot(result_eval_ln, result_train_ln[target_train].transpose()), axis=-1, keepdims=True)\n",
    "cos_eval = np.minimum(a, b)\n",
    "eval_eval['anomaly_score'] = cos_eval\n",
    "\n",
    "aucs = []\n",
    "p_aucs = []\n",
    "aucs_source = []\n",
    "p_aucs_source = []\n",
    "aucs_target = []\n",
    "p_aucs_target = []\n",
    "ths = []\n",
    "\n",
    "machine_list = eval_test['machine'].unique()\n",
    "for machine in machine_list:\n",
    "    auc_source_machine = []\n",
    "    auc_target_machine = []\n",
    "    p_auc_machine = []\n",
    "    temp = eval_test[eval_test['machine']==machine]\n",
    "    temp.drop(columns='machine', inplace=True)\n",
    "    temp['audio_path'] = temp['audio_path'].apply(lambda x: x.split('/')[-1])\n",
    "    temp = temp.sort_values(by='audio_path')\n",
    "    temp = temp.reset_index(drop=True)\n",
    "    true = temp['label'].values\n",
    "    cos = temp['anomaly_score'].values\n",
    "    fpr, tpr, thresholds = roc_curve(true, cos)\n",
    "    J = tpr - fpr\n",
    "    optimal_idx = np.argmax(J)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    ths.append(optimal_threshold)\n",
    "    # print('threshold: {}'.format(optimal_threshold))\n",
    "    decisions = (cos>optimal_threshold).astype(int)\n",
    "    accuracy = accuracy_score(true, decisions)\n",
    "    f1 = f1_score(true, decisions)\n",
    "    recall = recall_score(true, decisions)\n",
    "    precision = precision_score(true, decisions)\n",
    "    # print(accuracy, f1, recall, precision)\n",
    "\n",
    "    accuracy = (decisions==true).sum()/200\n",
    "    # print('accuracy: {}%'.format(accuracy*100))\n",
    "    auc = roc_auc_score(true, cos)\n",
    "    p_auc = roc_auc_score(true, cos, max_fpr=0.1)\n",
    "    aucs.append(auc)\n",
    "    p_aucs.append(p_auc)\n",
    "    # print('AUC of ' + machine + ': ' + str(auc * 100))\n",
    "    # print('pAUC of ' + machine + ': ' + str(p_auc * 100))\n",
    "    \n",
    "        \n",
    "    temp_source = temp[temp['domain']=='source']\n",
    "    true_source = temp_source['label'].values\n",
    "    cos_source = temp_source['anomaly_score'].values\n",
    "    auc = roc_auc_score(true_source, cos_source)\n",
    "    p_auc = roc_auc_score(true_source, cos_source, max_fpr=0.1)\n",
    "    aucs_source.append(auc)\n",
    "    p_aucs_source.append(p_auc)\n",
    "    auc_source_machine.append(auc)\n",
    "    p_auc_machine.append(p_auc)\n",
    "    # print('AUC for source domain of ' + machine + ': ' + str(auc * 100))\n",
    "    # print('pAUC for source domain of ' + machine + ': ' + str(p_auc * 100))\n",
    "        \n",
    "    temp_target = temp[temp['domain']=='target']\n",
    "    true_target = temp_target['label'].values\n",
    "    cos_target = temp_target['anomaly_score'].values\n",
    "    auc = roc_auc_score(true_target, cos_target)\n",
    "    p_auc = roc_auc_score(true_target, cos_target, max_fpr=0.1)\n",
    "    aucs_target.append(auc)\n",
    "    p_aucs_target.append(p_auc)\n",
    "    auc_target_machine.append(auc)\n",
    "    p_auc_machine.append(p_auc)\n",
    "    # print('AUC for target domain of ' + machine + ': ' + str(auc * 100))\n",
    "    # print('pAUC for target domain of ' + machine + ': ' + str(p_auc * 100))\n",
    "    \n",
    "    print(f'Machine: {machine}, hmean: {hmean(auc_source_machine+auc_target_machine+p_auc_machine)*100:.2f}')\n",
    "    \n",
    "    # print('==============================')\n",
    "    # print('==============================')\n",
    "    # print('==============================')\n",
    "\n",
    "mean_auc = hmean(aucs)\n",
    "# print('mean AUC: ' + str(mean_auc * 100))\n",
    "mean_p_auc = hmean(p_aucs)\n",
    "# print('mean pAUC: ' + str(mean_p_auc * 100))  \n",
    "mean_auc_source = hmean(aucs_source)\n",
    "# print('mean AUC for source domain: ' + str(mean_auc_source * 100))\n",
    "mean_p_auc_source = hmean(p_aucs_source)\n",
    "# print('mean pAUC for source domain: ' + str(mean_p_auc_source * 100))\n",
    "mean_auc_target = hmean(aucs_target)\n",
    "# print('mean AUC for target domain: ' + str(mean_auc_target * 100))\n",
    "mean_p_auc_target = hmean(p_aucs_target)\n",
    "# print('mean pAUC for target domain: ' + str(mean_p_auc_target * 100))\n",
    "\n",
    "score = hmean(aucs_source + aucs_target + p_aucs)\n",
    "print(f'final score : {score*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.81113469542821\n",
      "55.019889950673054\n"
     ]
    }
   ],
   "source": [
    "baseline1 = [66.98, 33.75, 48.77, 76.63, 46.92, 47.95, 62.01, 61.4, 57.58, 67.71, 55.24, 57.53, 70.4, 69.34, 55.65, 66.51, 56.01, 61.77, 51.07, 46.25, 52.42]\n",
    "baseline2 = [63.01, 37.35, 51.04, 61.99, 39.99, 48.21, 54.43, 51.58, 58.82, 79.37, 42.7, 53.44, 81.82, 74.35, 55.74, 75.35, 68.11, 49.05, 55.69, 53.61, 51.26]\n",
    "\n",
    "print(hmean(baseline1))\n",
    "print(hmean(baseline2))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
