{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WHOLE + MACHINE (mean of embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# weighted mean search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import hmean\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, recall_score, precision_score, auc, roc_curve\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_train = pd.read_csv('../processed_data/evaluation_train.csv')\n",
    "eval_test = pd.read_csv('../processed_data/evaluation_test.csv')\n",
    "eval_eval = pd.read_csv('../processed_data/evaluation_eval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/gearbox/test/section_00_target_test_normal_0027_noAttribute.wav'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_test.iloc[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result_emb/train_emb.pickle', 'rb') as f:\n",
    "    result_train = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "with open('result_emb/test_emb.pickle', 'rb') as f:\n",
    "    result_test = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "with open('result_emb/eval_emb.pickle', 'rb') as f:\n",
    "    result_eval = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "##############################################################\n",
    "\n",
    "with open('result_emb/train_machine_emb.pickle', 'rb') as f:\n",
    "    result_train_machine = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "with open('result_emb/test_machine_emb.pickle', 'rb') as f:\n",
    "    result_test_machine = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "with open('result_emb/eval_machine_emb.pickle', 'rb') as f:\n",
    "    result_eval_machine = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_norm(mat):\n",
    "    norm_mat = []\n",
    "    for line in mat:\n",
    "        temp = line / np.sqrt(sum(np.power(line, 2)))\n",
    "        norm_mat.append(temp)\n",
    "    norm_mat = np.array(norm_mat)\n",
    "    return norm_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_train_ln = length_norm(result_train)\n",
    "result_test_ln = length_norm(result_test)\n",
    "result_eval_ln = length_norm(result_eval)\n",
    "\n",
    "result_train_ln_machine = length_norm(result_train_machine)\n",
    "result_test_ln_machine = length_norm(result_test_machine)\n",
    "result_eval_ln_machine = length_norm(result_eval_machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<[0.62]<<<<<<<\n",
      "Machine: gearbox, hmean: 56.86\n",
      "Machine: ToyTrain, hmean: 53.99\n",
      "Machine: ToyCar, hmean: 48.34\n",
      "Machine: valve, hmean: 58.44\n",
      "Machine: slider, hmean: 65.60\n",
      "Machine: fan, hmean: 57.40\n",
      "Machine: bearing, hmean: 56.79\n",
      "final score : 56.68\n",
      "<<<<<<<[0.64]<<<<<<<\n",
      "Machine: gearbox, hmean: 56.50\n",
      "Machine: ToyTrain, hmean: 53.99\n",
      "Machine: ToyCar, hmean: 48.46\n",
      "Machine: valve, hmean: 58.27\n",
      "Machine: slider, hmean: 65.54\n",
      "Machine: fan, hmean: 57.37\n",
      "Machine: bearing, hmean: 56.20\n",
      "final score : 56.60\n",
      "<<<<<<<[0.65]<<<<<<<\n",
      "Machine: gearbox, hmean: 56.61\n",
      "Machine: ToyTrain, hmean: 54.02\n",
      "Machine: ToyCar, hmean: 48.43\n",
      "Machine: valve, hmean: 58.13\n",
      "Machine: slider, hmean: 65.77\n",
      "Machine: fan, hmean: 57.49\n",
      "Machine: bearing, hmean: 55.89\n",
      "final score : 56.64\n",
      "<<<<<<<[0.67]<<<<<<<\n",
      "Machine: gearbox, hmean: 56.68\n",
      "Machine: ToyTrain, hmean: 54.15\n",
      "Machine: ToyCar, hmean: 48.52\n",
      "Machine: valve, hmean: 58.13\n",
      "Machine: slider, hmean: 66.06\n",
      "Machine: fan, hmean: 57.53\n",
      "Machine: bearing, hmean: 55.50\n",
      "final score : 56.66\n"
     ]
    }
   ],
   "source": [
    "weights = [0.62, 0.64, 0.65, 0.67]\n",
    "\n",
    "for weight in weights:\n",
    "    print('<<<<<<<[{}]<<<<<<<'.format(weight))\n",
    "    result_train_mean = result_train_ln*weight + result_train_ln_machine*(1-weight)\n",
    "    result_test_mean = result_test_ln*weight + result_test_ln_machine*(1-weight)\n",
    "    result_eval_mean = result_eval_ln*weight + result_eval_ln_machine*(1-weight)\n",
    "\n",
    "    source_train = np.array(eval_train[eval_train['domain']=='source'].index)\n",
    "    target_train = np.array(eval_train[eval_train['domain']=='target'].index)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=16, random_state=42).fit(result_train_mean[source_train])\n",
    "    centers = kmeans.cluster_centers_\n",
    "\n",
    "    a = np.min(1-np.dot(result_train_mean, centers.transpose()), axis=-1, keepdims=True)\n",
    "    b = np.min(1-np.dot(result_train_mean, result_train_mean[target_train].transpose()), axis=-1, keepdims=True)\n",
    "    cos_train = np.minimum(a, b)\n",
    "    eval_train['anomaly_score'] = cos_train\n",
    "    \n",
    "    a = np.min(1-np.dot(result_test_mean, centers.transpose()), axis=-1, keepdims=True)\n",
    "    b = np.min(1-np.dot(result_test_mean, result_train_mean[target_train].transpose()), axis=-1, keepdims=True)\n",
    "    cos_test = np.minimum(a, b)\n",
    "    eval_test['anomaly_score'] = cos_test\n",
    "    \n",
    "    a = np.min(1-np.dot(result_eval_mean, centers.transpose()), axis=-1, keepdims=True)\n",
    "    b = np.min(1-np.dot(result_eval_mean, result_train_mean[target_train].transpose()), axis=-1, keepdims=True)\n",
    "    cos_eval = np.minimum(a, b)\n",
    "    eval_eval['anomaly_score'] = cos_eval\n",
    "\n",
    "    aucs = []\n",
    "    p_aucs = []\n",
    "    aucs_source = []\n",
    "    p_aucs_source = []\n",
    "    aucs_target = []\n",
    "    p_aucs_target = []\n",
    "    ths = []\n",
    "    \n",
    "    machine_list = eval_test['machine'].unique()\n",
    "    for machine in machine_list:\n",
    "        auc_source_machine = []\n",
    "        auc_target_machine = []\n",
    "        p_auc_machine = []\n",
    "        temp = eval_test[eval_test['machine']==machine]\n",
    "        temp.drop(columns='machine', inplace=True)\n",
    "        temp['audio_path'] = temp['audio_path'].apply(lambda x: x.split('/')[-1])\n",
    "        temp = temp.sort_values(by='audio_path')\n",
    "        temp = temp.reset_index(drop=True)\n",
    "        true = temp['label'].values\n",
    "        cos = temp['anomaly_score'].values\n",
    "        fpr, tpr, thresholds = roc_curve(true, cos)\n",
    "        J = tpr - fpr\n",
    "        optimal_idx = np.argmax(J)\n",
    "        optimal_threshold = thresholds[optimal_idx]\n",
    "        ths.append(optimal_threshold)\n",
    "        # print('threshold: {}'.format(optimal_threshold))\n",
    "        decisions = (cos>optimal_threshold).astype(int)\n",
    "        accuracy = accuracy_score(true, decisions)\n",
    "        f1 = f1_score(true, decisions)\n",
    "        recall = recall_score(true, decisions)\n",
    "        precision = precision_score(true, decisions)\n",
    "        # print(accuracy, f1, recall, precision)\n",
    "\n",
    "        accuracy = (decisions==true).sum()/200\n",
    "        # print('accuracy: {}%'.format(accuracy*100))\n",
    "        auc = roc_auc_score(true, cos)\n",
    "        p_auc = roc_auc_score(true, cos, max_fpr=0.1)\n",
    "        aucs.append(auc)\n",
    "        p_aucs.append(p_auc)\n",
    "        # print('AUC of ' + machine + ': ' + str(auc * 100))\n",
    "        # print('pAUC of ' + machine + ': ' + str(p_auc * 100))\n",
    "        \n",
    "            \n",
    "        temp_source = temp[temp['domain']=='source']\n",
    "        true_source = temp_source['label'].values\n",
    "        cos_source = temp_source['anomaly_score'].values\n",
    "        auc = roc_auc_score(true_source, cos_source)\n",
    "        p_auc = roc_auc_score(true_source, cos_source, max_fpr=0.1)\n",
    "        aucs_source.append(auc)\n",
    "        p_aucs_source.append(p_auc)\n",
    "        auc_source_machine.append(auc)\n",
    "        p_auc_machine.append(p_auc)\n",
    "        # print('AUC for source domain of ' + machine + ': ' + str(auc * 100))\n",
    "        # print('pAUC for source domain of ' + machine + ': ' + str(p_auc * 100))\n",
    "            \n",
    "        temp_target = temp[temp['domain']=='target']\n",
    "        true_target = temp_target['label'].values\n",
    "        cos_target = temp_target['anomaly_score'].values\n",
    "        auc = roc_auc_score(true_target, cos_target)\n",
    "        p_auc = roc_auc_score(true_target, cos_target, max_fpr=0.1)\n",
    "        aucs_target.append(auc)\n",
    "        p_aucs_target.append(p_auc)\n",
    "        auc_target_machine.append(auc)\n",
    "        p_auc_machine.append(p_auc)\n",
    "        # print('AUC for target domain of ' + machine + ': ' + str(auc * 100))\n",
    "        # print('pAUC for target domain of ' + machine + ': ' + str(p_auc * 100))\n",
    "        \n",
    "        print(f'Machine: {machine}, hmean: {hmean(auc_source_machine+auc_target_machine+p_auc_machine)*100:.2f}')\n",
    "        \n",
    "        # print('==============================')\n",
    "        # print('==============================')\n",
    "        # print('==============================')\n",
    "\n",
    "    mean_auc = hmean(aucs)\n",
    "    # print('mean AUC: ' + str(mean_auc * 100))\n",
    "    mean_p_auc = hmean(p_aucs)\n",
    "    # print('mean pAUC: ' + str(mean_p_auc * 100))  \n",
    "    mean_auc_source = hmean(aucs_source)\n",
    "    # print('mean AUC for source domain: ' + str(mean_auc_source * 100))\n",
    "    mean_p_auc_source = hmean(p_aucs_source)\n",
    "    # print('mean pAUC for source domain: ' + str(mean_p_auc_source * 100))\n",
    "    mean_auc_target = hmean(aucs_target)\n",
    "    # print('mean AUC for target domain: ' + str(mean_auc_target * 100))\n",
    "    mean_p_auc_target = hmean(p_aucs_target)\n",
    "    # print('mean pAUC for target domain: ' + str(mean_p_auc_target * 100))\n",
    "\n",
    "    score = hmean(aucs_source + aucs_target + p_aucs)\n",
    "    print(f'final score : {score*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [0.62, 0.64, 0.65, 0.67]\n",
    "\n",
    "for i, weight in enumerate(weights):\n",
    "    result_train_mean = result_train_ln*weight + result_train_ln_machine*(1-weight)\n",
    "    result_eval_mean = result_eval_ln*weight + result_eval_ln_machine*(1-weight)\n",
    "\n",
    "    source_train = np.array(eval_train[eval_train['domain']=='source'].index)\n",
    "    target_train = np.array(eval_train[eval_train['domain']=='target'].index)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=16, random_state=42).fit(result_train_mean[source_train])\n",
    "    centers = kmeans.cluster_centers_\n",
    "    \n",
    "    a = np.min(1-np.dot(result_train_mean, centers.transpose()), axis=-1, keepdims=True)\n",
    "    b = np.min(1-np.dot(result_train_mean, result_train_mean[target_train].transpose()), axis=-1, keepdims=True)\n",
    "    cos_train = np.minimum(a, b)\n",
    "    eval_train['anomaly_score'] = cos_train\n",
    "    \n",
    "    a = np.min(1-np.dot(result_eval_mean, centers.transpose()), axis=-1, keepdims=True)\n",
    "    b = np.min(1-np.dot(result_eval_mean, result_train_mean[target_train].transpose()), axis=-1, keepdims=True)\n",
    "    cos = np.minimum(a, b)\n",
    "\n",
    "    eval_eval['anomaly_score'] = cos\n",
    "\n",
    "    for machine in eval_eval['machine'].unique():\n",
    "        temp = eval_eval[eval_eval['machine']==machine]\n",
    "        temp.drop(columns=['machine'], inplace=True)\n",
    "        temp['audio_path'] = temp['audio_path'].apply(lambda x: x.split('/')[-1])\n",
    "        temp = temp.sort_values(by='audio_path')\n",
    "        temp = temp.reset_index(drop=True)\n",
    "        temp.to_csv(f'submission/task2/Kim_CAU_task2_{i+1}/anomaly_score_{machine}_section_00_test.csv', encoding='utf-8', index=False, header=False)\n",
    "        \n",
    "    for machine in eval_eval['machine'].unique():\n",
    "        train = eval_train[eval_train['machine']==machine]\n",
    "        threshold = np.quantile(train['anomaly_score'], 0.8)\n",
    "        temp = eval_eval[eval_eval['machine']==machine]\n",
    "        temp['decisions'] = (temp['anomaly_score']>threshold).astype(int)\n",
    "        temp.drop(columns=['machine', 'anomaly_score'], inplace=True)\n",
    "        temp['audio_path'] = temp['audio_path'].apply(lambda x: x.split('/')[-1])\n",
    "        temp = temp.sort_values(by='audio_path')\n",
    "        temp = temp.reset_index(drop=True)\n",
    "        temp.to_csv(f'submission/task2/Kim_CAU_task2_{i+1}/decision_result_{machine}_section_00_test.csv', encoding='utf-8', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    16000.000000\n",
       "mean         0.501621\n",
       "std          0.146535\n",
       "min          0.094755\n",
       "25%          0.441864\n",
       "50%          0.464686\n",
       "75%          0.524569\n",
       "max          0.892598\n",
       "Name: anomaly_score, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_train['anomaly_score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1400.000000\n",
       "mean        0.507871\n",
       "std         0.095051\n",
       "min         0.387952\n",
       "25%         0.449427\n",
       "50%         0.472469\n",
       "75%         0.523302\n",
       "max         0.893043\n",
       "Name: anomaly_score, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_test['anomaly_score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1800.000000\n",
       "mean        0.474221\n",
       "std         0.137229\n",
       "min         0.096101\n",
       "25%         0.422052\n",
       "50%         0.460519\n",
       "75%         0.512726\n",
       "max         0.867173\n",
       "Name: anomaly_score, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_eval['anomaly_score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToothBrush\n",
      "count    200.000000\n",
      "mean       0.460690\n",
      "std        0.035413\n",
      "min        0.416045\n",
      "25%        0.442232\n",
      "50%        0.443802\n",
      "75%        0.470559\n",
      "max        0.662683\n",
      "Name: anomaly_score, dtype: float64\n",
      "Scanner\n",
      "count    200.000000\n",
      "mean       0.462111\n",
      "std        0.006575\n",
      "min        0.433706\n",
      "25%        0.460426\n",
      "50%        0.461020\n",
      "75%        0.461741\n",
      "max        0.524528\n",
      "Name: anomaly_score, dtype: float64\n",
      "HoveringDrone\n",
      "count    200.000000\n",
      "mean       0.455211\n",
      "std        0.018358\n",
      "min        0.444622\n",
      "25%        0.448808\n",
      "50%        0.450495\n",
      "75%        0.455517\n",
      "max        0.634229\n",
      "Name: anomaly_score, dtype: float64\n",
      "HairDryer\n",
      "count    200.000000\n",
      "mean       0.522754\n",
      "std        0.124527\n",
      "min        0.363164\n",
      "25%        0.425978\n",
      "50%        0.465295\n",
      "75%        0.618819\n",
      "max        0.794475\n",
      "Name: anomaly_score, dtype: float64\n",
      "3DPrinter\n",
      "count    200.000000\n",
      "mean       0.218738\n",
      "std        0.076511\n",
      "min        0.096101\n",
      "25%        0.119212\n",
      "50%        0.263072\n",
      "75%        0.276277\n",
      "max        0.374105\n",
      "Name: anomaly_score, dtype: float64\n",
      "ToyCircuit\n",
      "count    200.000000\n",
      "mean       0.589252\n",
      "std        0.088641\n",
      "min        0.447657\n",
      "25%        0.534819\n",
      "50%        0.571411\n",
      "75%        0.609128\n",
      "max        0.833178\n",
      "Name: anomaly_score, dtype: float64\n",
      "RoboticArm\n",
      "count    200.000000\n",
      "mean       0.650433\n",
      "std        0.137929\n",
      "min        0.432485\n",
      "25%        0.526536\n",
      "50%        0.648178\n",
      "75%        0.786405\n",
      "max        0.867173\n",
      "Name: anomaly_score, dtype: float64\n",
      "BrushlessMotor\n",
      "count    200.000000\n",
      "mean       0.510494\n",
      "std        0.001290\n",
      "min        0.507524\n",
      "25%        0.509515\n",
      "50%        0.510864\n",
      "75%        0.511369\n",
      "max        0.512951\n",
      "Name: anomaly_score, dtype: float64\n",
      "AirCompressor\n",
      "count    200.000000\n",
      "mean       0.398306\n",
      "std        0.009153\n",
      "min        0.392088\n",
      "25%        0.395482\n",
      "50%        0.397232\n",
      "75%        0.399441\n",
      "max        0.517307\n",
      "Name: anomaly_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for machine in eval_eval['machine'].unique():\n",
    "    print(machine)\n",
    "    print(eval_eval[eval_eval['machine']==machine]['anomaly_score'].describe())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
